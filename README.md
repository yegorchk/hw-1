# HW-1

## Что за данные
Датасет про уровни ожирения. Таргет: `NObeyesdad` — 7 классов:
- Insufficient_Weight
- Normal_Weight
- Overweight_Level_I
- Overweight_Level_II
- Obesity_Type_I
- Obesity_Type_II
- Obesity_Type_III

Размер: 2111 строк, 16 признаков (числовые + категориальные).

---

## EDA 

### Баланс классов
Классы распределены довольно ровно (примерно 272–351 объектов на класс).  
Вывод: сильного дисбаланса нет → можно спокойно смотреть `accuracy`, но дополнительно использую `macro-F1`, потому что классов 7.

### Пропуски
Пропусков нет.  
Вывод: иммутация не нужна.

### Типы признаков
Есть числовые (Age, Height, Weight, …) и категориальные (Gender, CALC, FAVC, …).  
Вывод: для моделей типа Logistic Regression нужно делать OneHot для категориальных, и чаще всего scaling для числовых.

### Корреляции
Сильных корреляций нет (максимальная около 0.46 между Height и Weight).  
Вывод: жёсткой мультиколлинеарности нет, линейные модели не должны “страдать” из-за дублирующихся числовых признаков.

### Числовые признаки по классам
По средним значениям видно, что `Weight` сильно меняется между классами (это главный сигнал). `Height` меняется слабее.

---

## Гипотезы и результаты

### 1) BMI помогает
Гипотеза: добавление ИМТ улучшит качество.

$$
BMI = \frac{Weight}{Height^2}
$$

Проверка: Logistic Regression (5-fold CV), сравнил без BMI и с BMI.

Результат:
- без BMI: accuracy 0.8801, macro-F1 0.8762
- с BMI:  accuracy 0.9105, macro-F1 0.9077

Вывод: гипотеза подтвердилась, BMI даёт заметный прирост (~+0.03).

---

### 2) Категориальные признаки в LogReg (с BMI) не дали прироста
Гипотеза: добавление категориальных признаков (one-hot) улучшит качество.

Проверка: LogReg (5-fold CV)
- только числовые (+BMI)
- числовые (+BMI) + категориальные (one-hot)

Результат:
- num_only(+BMI): accuracy 0.9147, macro-F1 0.9120
- num+cat(+BMI):  accuracy 0.9105, macro-F1 0.9077

Вывод: гипотеза не подтвердилась (в этой модели стало чуть хуже)

---

### 3) Дерево решений нужно ограничивать по глубине
Гипотеза: дерево без контроля сложности может быть не оптимальным, а подбор `max_depth` улучшит качество.

Проверка: DecisionTree с разными `max_depth` (5-fold CV).

Результат (лучшее в переборе):
- max_depth = 7: accuracy ~0.9749, macro-F1 ~0.9747

Вывод: гипотеза подтвердилась — глубину есть смысл подбирать, слишком маленькая глубина сильно ухудшает качество (недообучение).

---

### 4) RandomForest лучше одного дерева
Гипотеза: ансамбль деревьев (RandomForest) даст прирост относительно одного дерева.

Проверка: сравнил DecisionTree(depth=7) vs RandomForest(300) (5-fold CV).

Результат:
- DecisionTree(depth=7): accuracy 0.9749, macro-F1 0.9747
- RandomForest(300):     accuracy 0.9820

Вывод: гипотеза подтвердилась — RandomForest дал прирост по accuracy и стабильность примерно такая же.

---

### 5) class_weight='balanced' почти не влияет
Гипотеза: так как классы примерно сбалансированы, веса классов не дадут заметного эффекта.

Проверка: LogReg(+BMI) без весов vs с `class_weight='balanced'`.

Результат:
- без весов: accuracy 0.9105, macro-F1 0.9077
- balanced:  accuracy 0.9109, macro-F1 0.9082

Вывод: гипотеза подтвердилась — эффект минимальный.

---

## Итог
- Самый простой и сильный feature engineering здесь — **BMI**.
- Деревья/ансамбли на этих данных дают очень высокое качество (RandomForest лучше одиночного дерева).
- Категориальные признаки в связке с LogReg (+BMI) явно не улучшили качество.

Файлы:
- `research.ipynb` — EDA + проверки гипотез
- `ObesityDataSet_raw_and_data_sinthetic.csv` — данные